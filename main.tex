% ---- ETD Document Class and Useful Packages ---- %
% This LaTeX template for Ph.D. dissertations at the University of Hanyang University.
% This template is adapted from the LaTeX template for the University of Chicago doctoral thesis:https://github.com/k4rtik/uchicago-dissertation
% Authors: Yu Zhao
\documentclass[a4paper,12pt]{HYU}
\usepackage{geometry}
\usepackage{CJKutf8}
\usepackage{algorithmic}
\usepackage{algorithm}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{1}
\usepackage{kotex}
\usepackage{mathptmx}
\usepackage{xspace}
\usepackage{soul}
\usepackage{romannum}
\usepackage{bm}
\def\mathbi#1{\textbf{\em #1}}
\def\mathbi#1{\bm{#1}}
\usepackage{multirow}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usepackage{rotating}
\makeatletter
\renewenvironment{abstract}{%
    \if@twocolumn
      \section*{\abstractname}%
    \else %% <- here I've removed \small
      \begin{center}%
        {\bfseries \Large\abstractname\vspace{\z@}}%  %% <- here I've added \Large
      \end{center}%
      \quotation
    \fi}
    {\if@twocolumn\else\endquotation\fi}
\makeatother

\usepackage[utf8]{inputenc}
\setlength{\parindent}{2em}
\usepackage[T1]{fontenc}
\usepackage{indentfirst} 
\usepackage{subcaption,graphicx}
\usepackage{mathtools}  % loads amsmath
\usepackage{amssymb}    % loads amsfonts
\usepackage{amsthm}
\usepackage{nomencl}
\usepackage{array}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
%For the abbreviations page
\newboolean{Figure}
\setboolean{Figure}{false}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}{Assumption}
\usepackage{tikz}
\newcommand*{\circled}[1]{\lower.7ex\hbox{\tikz\draw (0pt, 0pt)%
    circle (.5em) node {\makebox[1em][c]{\small #1}};}}
%% Use these commands to set biographic information for the title page:
\newcommand{\thesistitle}{Dissertation Title}
\newcommand{\thesisauthor}{Dissertation Author}
\department{Computer Science and Engineering}
\division{Dissertation Division}
\degree{Doctor of Philosophy}
\date{August 2025}
\youradvisor{Jongwon Yoon}

\definecolor{pt_stage}{HTML}{FFF47A}
\definecolor{at_stage}{HTML}{AED6CE}

\title{Towards Realistic Dense Video Captioning: Gradual, Parallel, and Adversarial Pathways}
\author{Wangyu Choi}

%% Use these commands to set a dedication and epigraph text
\dedication{Dedication Text}
\epigraph{Epigraph Text}

\usepackage{doi}
\usepackage{xurl}
\hypersetup{bookmarksnumbered,
            unicode,
            linktoc=all,
            pdftitle={\thesistitle},
            pdfauthor={\thesisauthor},
            pdfsubject={},                                % Add subject/description
            % pdfkeywords={keyword1, keyword2, keyword3}, % Uncomment and revise keywords
            pdfborder={0 0 0}}
% See https://github.com/k4rtik/ucetd-latex/issues/1
\makeatletter
\let\ORG@hyper@linkstart\hyper@linkstart
\protected\def\hyper@linkstart#1#2{%
  \lowercase{\ORG@hyper@linkstart{#1}{#2}}}
\makeatother

\begin{document}
%% Basic setup commands
% If you don't want a title page comment out the next line and uncomment the line after it:
\maketitle
%\omittitle
%\geometry{left=3.5cm,right=3.5cm,top=4cm,bottom=4cm}
% These lines can be commented out to disable the copyright/dedication/epigraph pages
% \makecopyright
% \makededication
% \makeepigraph


%% Make the various tables of contents
\newgeometry{left=3.5cm, right=3.5cm, top=4cm, bottom=4cm} 
\tableofcontents
\listoffigures
\listoftables
%\newpage
\abbreviations
\makenomenclature
\renewcommand{\nomname}{List of Abbreviations}
\printnomenclature
\hfill % add blank space




\newpage
\begin{abstract}
\begin{center}
\textbf{\fontsize{13pt}{13} \selectfont  Towards Realistic Dense Video Captioning: Gradual, Parallel, and Adversarial Pathways}
\end{center}
\addcontentsline{toc}{chapter}{Abstract}
Dense video captioning, which aims to temporally localize multiple events within untrimmed videos and generate corresponding natural language descriptions, faces fundamental challenges including sequential processing limitations, overlapping event detection difficulties, annotation scarcity, and the inherent nondeterminism in human interpretation. This dissertation presents four complementary approaches that systematically address these challenges while advancing the state-of-the-art in dense video captioning.

First, we propose the Step-by-Step (SBS) framework, a human-inspired progressive approach that explicitly predicts the number of events and progressively detects overlapping event boundaries. Unlike conventional proposal-based methods, SBS employs content-aware event counting and actionness-weighted temporal IoU algorithms, achieving superior F1 scores (58.56) while generating significantly more events per video compared to existing methods.

Second, we introduce the Parallel Pathway Dense Video Captioning (PPVC) framework that performs event localization and caption generation simultaneously, eliminating error propagation inherent in sequential "localize-then-describe" pipelines. Through bottleneck-free information flow and multi-stack cross-attention mechanisms, PPVC achieves competitive performance with METEOR scores of 7.91 on ActivityNet Captions.

Third, we develop the Pretraining-based Weakly Supervised Dense Video Captioning (PWS-DVC) framework that leverages large-scale clip-level caption datasets for model initialization without requiring explicit event-level annotations. PWS-DVC demonstrates state-of-the-art performance among weakly supervised methods, achieving METEOR scores of 8.22 on ActivityNet Captions while significantly reducing annotation requirements.

Finally, we present the Adversarial Dense Video Captioning (ADVC) framework that explicitly models the nondeterministic nature of video interpretation through adversarial learning. By capturing the distribution of valid interpretations rather than assuming deterministic ground truth, ADVC generates diverse yet coherent outputs, achieving METEOR scores of 8.28 on ActivityNet Captions and 7.34 on YouCook2.

Comprehensive experimental validation on standard benchmarks including ActivityNet Captions and YouCook2 demonstrates that our approaches not only achieve superior quantitative performance but also address fundamental limitations in existing methods. This work establishes new paradigms for dense video captioning that better reflect the complexity and subjectivity inherent in real-world video understanding tasks.
\end{abstract}

\begin{flushleft}
\hspace{6.4cm} {\fontsize{11pt}{16} \selectfont Wangyu Choi}\\
\hspace{6.4cm} {\fontsize{11pt}{16} \selectfont Dept. of Computer Science and Engineering} \\
\hspace{6.4cm} {\fontsize{11pt}{16} \selectfont The Graduate School}\\
\hspace{6.4cm} {\fontsize{11pt}{16} \selectfont Hanyang University}
\end{flushleft}


\mainmatter
% Main body of text follows
\input{chapter1}
\input{chapter2}
\input{chapter3}
\input{chapter4}
\input{chapter5}
\input{chapter6}
\input{chapter7}

% Introductory stuff
\makebibliography
% \nocite{*}
\restoregeometry
% \chapter{A Chapter}
% \section{Introduction}
% Intro to chapter one

\abstractinkorea

% \begin{CJK}{UTF8}{}
%  \CJKfamily{mj}
%  \vspace{-1.5cm}
%  \centering{{\fontsize{16pt}{16} \selectfont  국문요지}}
%  \begin{verbatim}
%  \end{verbatim}
% \end{CJK}

% \appendixs
%\section*{}


\acknowledgments

% Enter Acknowledgements here

% \publications
% Enter your publications here

\end{document}
